{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK</th>\n",
       "      <th>BID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LAST</th>\n",
       "      <th>LOW</th>\n",
       "      <th>MID</th>\n",
       "      <th>VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7926.700</td>\n",
       "      <td>7925.800</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>8277.800</td>\n",
       "      <td>7926.50</td>\n",
       "      <td>7716.600</td>\n",
       "      <td>7926.250</td>\n",
       "      <td>49132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8187.900</td>\n",
       "      <td>8183.800</td>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>8516.900</td>\n",
       "      <td>8177.40</td>\n",
       "      <td>7835.900</td>\n",
       "      <td>8185.850</td>\n",
       "      <td>58065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8480.800</td>\n",
       "      <td>8479.900</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>8674.400</td>\n",
       "      <td>8481.00</td>\n",
       "      <td>8364.800</td>\n",
       "      <td>8480.350</td>\n",
       "      <td>30079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8643.800</td>\n",
       "      <td>8639.700</td>\n",
       "      <td>2018-03-24</td>\n",
       "      <td>9050.300</td>\n",
       "      <td>8639.70</td>\n",
       "      <td>8556.000</td>\n",
       "      <td>8641.750</td>\n",
       "      <td>44565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8690.900</td>\n",
       "      <td>8690.200</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>9095.920</td>\n",
       "      <td>8690.90</td>\n",
       "      <td>8450.000</td>\n",
       "      <td>8690.550</td>\n",
       "      <td>54383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8870.100</td>\n",
       "      <td>8870.000</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>9177.500</td>\n",
       "      <td>8870.00</td>\n",
       "      <td>8752.000</td>\n",
       "      <td>8870.050</td>\n",
       "      <td>42946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8932.000</td>\n",
       "      <td>8931.900</td>\n",
       "      <td>2018-03-20</td>\n",
       "      <td>9040.000</td>\n",
       "      <td>8932.00</td>\n",
       "      <td>8305.100</td>\n",
       "      <td>8931.950</td>\n",
       "      <td>55419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8500.000</td>\n",
       "      <td>8499.900</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>8717.000</td>\n",
       "      <td>8505.00</td>\n",
       "      <td>8085.700</td>\n",
       "      <td>8499.950</td>\n",
       "      <td>74323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8149.100</td>\n",
       "      <td>8148.800</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>8300.000</td>\n",
       "      <td>8147.00</td>\n",
       "      <td>7240.000</td>\n",
       "      <td>8148.950</td>\n",
       "      <td>87116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7993.100</td>\n",
       "      <td>7993.000</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>8515.900</td>\n",
       "      <td>7993.00</td>\n",
       "      <td>7728.100</td>\n",
       "      <td>7993.050</td>\n",
       "      <td>50245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8488.300</td>\n",
       "      <td>8481.000</td>\n",
       "      <td>2018-03-16</td>\n",
       "      <td>8604.500</td>\n",
       "      <td>8494.30</td>\n",
       "      <td>7902.000</td>\n",
       "      <td>8484.650</td>\n",
       "      <td>54272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8269.000</td>\n",
       "      <td>8268.900</td>\n",
       "      <td>2018-03-15</td>\n",
       "      <td>8418.000</td>\n",
       "      <td>8267.70</td>\n",
       "      <td>7665.100</td>\n",
       "      <td>8268.950</td>\n",
       "      <td>83733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8175.100</td>\n",
       "      <td>8175.000</td>\n",
       "      <td>2018-03-14</td>\n",
       "      <td>9439.600</td>\n",
       "      <td>8175.10</td>\n",
       "      <td>7916.000</td>\n",
       "      <td>8175.050</td>\n",
       "      <td>77582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9150.600</td>\n",
       "      <td>9150.500</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>9482.400</td>\n",
       "      <td>9150.60</td>\n",
       "      <td>8822.000</td>\n",
       "      <td>9150.550</td>\n",
       "      <td>62993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9098.500</td>\n",
       "      <td>9098.400</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>9900.000</td>\n",
       "      <td>9098.40</td>\n",
       "      <td>8770.000</td>\n",
       "      <td>9098.450</td>\n",
       "      <td>67217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9485.100</td>\n",
       "      <td>9482.100</td>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>9729.000</td>\n",
       "      <td>9485.20</td>\n",
       "      <td>8428.000</td>\n",
       "      <td>9483.600</td>\n",
       "      <td>70288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8807.800</td>\n",
       "      <td>8807.700</td>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>9506.400</td>\n",
       "      <td>8807.70</td>\n",
       "      <td>8670.900</td>\n",
       "      <td>8807.750</td>\n",
       "      <td>52902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9303.000</td>\n",
       "      <td>9302.400</td>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>9428.000</td>\n",
       "      <td>9303.00</td>\n",
       "      <td>8342.000</td>\n",
       "      <td>9302.700</td>\n",
       "      <td>98498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9352.600</td>\n",
       "      <td>9352.500</td>\n",
       "      <td>2018-03-08</td>\n",
       "      <td>10112.000</td>\n",
       "      <td>9352.57</td>\n",
       "      <td>9025.000</td>\n",
       "      <td>9352.550</td>\n",
       "      <td>67030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9884.100</td>\n",
       "      <td>9880.000</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>10899.000</td>\n",
       "      <td>9880.00</td>\n",
       "      <td>9400.000</td>\n",
       "      <td>9882.050</td>\n",
       "      <td>75295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10685.000</td>\n",
       "      <td>10683.000</td>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>11553.000</td>\n",
       "      <td>10683.00</td>\n",
       "      <td>10567.000</td>\n",
       "      <td>10684.000</td>\n",
       "      <td>45055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11545.000</td>\n",
       "      <td>11543.000</td>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>11700.000</td>\n",
       "      <td>11545.00</td>\n",
       "      <td>11400.000</td>\n",
       "      <td>11544.000</td>\n",
       "      <td>26849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11535.000</td>\n",
       "      <td>11534.000</td>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>11549.000</td>\n",
       "      <td>11534.00</td>\n",
       "      <td>11050.000</td>\n",
       "      <td>11534.500</td>\n",
       "      <td>27917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11464.000</td>\n",
       "      <td>11463.000</td>\n",
       "      <td>2018-03-03</td>\n",
       "      <td>11530.000</td>\n",
       "      <td>11463.00</td>\n",
       "      <td>11013.000</td>\n",
       "      <td>11463.500</td>\n",
       "      <td>30574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11022.000</td>\n",
       "      <td>11021.000</td>\n",
       "      <td>2018-03-02</td>\n",
       "      <td>11189.000</td>\n",
       "      <td>11022.00</td>\n",
       "      <td>10762.000</td>\n",
       "      <td>11021.500</td>\n",
       "      <td>29056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10940.000</td>\n",
       "      <td>10934.000</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>11095.000</td>\n",
       "      <td>10940.00</td>\n",
       "      <td>10210.000</td>\n",
       "      <td>10937.000</td>\n",
       "      <td>33718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10295.000</td>\n",
       "      <td>10294.000</td>\n",
       "      <td>2018-02-28</td>\n",
       "      <td>11065.000</td>\n",
       "      <td>10294.00</td>\n",
       "      <td>10261.000</td>\n",
       "      <td>10294.500</td>\n",
       "      <td>44130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10669.000</td>\n",
       "      <td>10668.000</td>\n",
       "      <td>2018-02-27</td>\n",
       "      <td>10888.000</td>\n",
       "      <td>10668.00</td>\n",
       "      <td>10125.000</td>\n",
       "      <td>10668.500</td>\n",
       "      <td>39458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10301.000</td>\n",
       "      <td>10300.000</td>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>10439.000</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>9359.900</td>\n",
       "      <td>10300.500</td>\n",
       "      <td>45945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9541.000</td>\n",
       "      <td>9536.300</td>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>9840.000</td>\n",
       "      <td>9534.50</td>\n",
       "      <td>9280.400</td>\n",
       "      <td>9538.650</td>\n",
       "      <td>30710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>446.970</td>\n",
       "      <td>446.400</td>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>451.400</td>\n",
       "      <td>446.97</td>\n",
       "      <td>442.510</td>\n",
       "      <td>446.685</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>447.400</td>\n",
       "      <td>447.000</td>\n",
       "      <td>2014-05-14</td>\n",
       "      <td>448.000</td>\n",
       "      <td>447.00</td>\n",
       "      <td>437.810</td>\n",
       "      <td>447.200</td>\n",
       "      <td>3086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>439.000</td>\n",
       "      <td>437.810</td>\n",
       "      <td>2014-05-13</td>\n",
       "      <td>442.000</td>\n",
       "      <td>437.82</td>\n",
       "      <td>434.010</td>\n",
       "      <td>438.405</td>\n",
       "      <td>1913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>439.410</td>\n",
       "      <td>439.400</td>\n",
       "      <td>2014-05-12</td>\n",
       "      <td>442.000</td>\n",
       "      <td>439.41</td>\n",
       "      <td>431.800</td>\n",
       "      <td>439.405</td>\n",
       "      <td>3454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>436.850</td>\n",
       "      <td>436.810</td>\n",
       "      <td>2014-05-11</td>\n",
       "      <td>459.650</td>\n",
       "      <td>436.85</td>\n",
       "      <td>430.000</td>\n",
       "      <td>436.830</td>\n",
       "      <td>11882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>455.200</td>\n",
       "      <td>455.000</td>\n",
       "      <td>2014-05-10</td>\n",
       "      <td>457.000</td>\n",
       "      <td>455.00</td>\n",
       "      <td>448.200</td>\n",
       "      <td>455.100</td>\n",
       "      <td>2438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>443.490</td>\n",
       "      <td>442.000</td>\n",
       "      <td>2014-05-08</td>\n",
       "      <td>450.590</td>\n",
       "      <td>442.00</td>\n",
       "      <td>438.600</td>\n",
       "      <td>442.745</td>\n",
       "      <td>4046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>446.000</td>\n",
       "      <td>445.720</td>\n",
       "      <td>2014-05-07</td>\n",
       "      <td>453.600</td>\n",
       "      <td>446.00</td>\n",
       "      <td>424.249</td>\n",
       "      <td>445.860</td>\n",
       "      <td>10468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>430.900</td>\n",
       "      <td>429.500</td>\n",
       "      <td>2014-05-06</td>\n",
       "      <td>435.390</td>\n",
       "      <td>430.90</td>\n",
       "      <td>419.400</td>\n",
       "      <td>430.200</td>\n",
       "      <td>6980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>432.237</td>\n",
       "      <td>430.750</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>444.400</td>\n",
       "      <td>430.75</td>\n",
       "      <td>425.600</td>\n",
       "      <td>431.493</td>\n",
       "      <td>5940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>436.900</td>\n",
       "      <td>436.200</td>\n",
       "      <td>2014-05-04</td>\n",
       "      <td>441.950</td>\n",
       "      <td>436.40</td>\n",
       "      <td>429.000</td>\n",
       "      <td>436.550</td>\n",
       "      <td>4157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>441.380</td>\n",
       "      <td>440.300</td>\n",
       "      <td>2014-05-03</td>\n",
       "      <td>455.000</td>\n",
       "      <td>441.30</td>\n",
       "      <td>430.000</td>\n",
       "      <td>440.840</td>\n",
       "      <td>7611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>449.850</td>\n",
       "      <td>449.460</td>\n",
       "      <td>2014-05-02</td>\n",
       "      <td>461.670</td>\n",
       "      <td>449.85</td>\n",
       "      <td>443.000</td>\n",
       "      <td>449.655</td>\n",
       "      <td>3298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>460.090</td>\n",
       "      <td>459.100</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>463.530</td>\n",
       "      <td>460.10</td>\n",
       "      <td>446.990</td>\n",
       "      <td>459.595</td>\n",
       "      <td>5339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>449.370</td>\n",
       "      <td>449.360</td>\n",
       "      <td>2014-04-30</td>\n",
       "      <td>453.600</td>\n",
       "      <td>449.37</td>\n",
       "      <td>432.000</td>\n",
       "      <td>449.365</td>\n",
       "      <td>6877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>447.000</td>\n",
       "      <td>445.550</td>\n",
       "      <td>2014-04-29</td>\n",
       "      <td>454.000</td>\n",
       "      <td>445.54</td>\n",
       "      <td>434.000</td>\n",
       "      <td>446.275</td>\n",
       "      <td>8521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>445.500</td>\n",
       "      <td>445.400</td>\n",
       "      <td>2014-04-28</td>\n",
       "      <td>450.000</td>\n",
       "      <td>445.40</td>\n",
       "      <td>423.110</td>\n",
       "      <td>445.450</td>\n",
       "      <td>16467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>445.910</td>\n",
       "      <td>445.500</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>465.600</td>\n",
       "      <td>445.00</td>\n",
       "      <td>440.000</td>\n",
       "      <td>445.705</td>\n",
       "      <td>5959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>459.000</td>\n",
       "      <td>457.600</td>\n",
       "      <td>2014-04-26</td>\n",
       "      <td>469.190</td>\n",
       "      <td>457.60</td>\n",
       "      <td>449.800</td>\n",
       "      <td>458.300</td>\n",
       "      <td>8578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>465.955</td>\n",
       "      <td>463.790</td>\n",
       "      <td>2014-04-25</td>\n",
       "      <td>504.960</td>\n",
       "      <td>463.79</td>\n",
       "      <td>441.300</td>\n",
       "      <td>464.872</td>\n",
       "      <td>30376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>497.980</td>\n",
       "      <td>497.000</td>\n",
       "      <td>2014-04-24</td>\n",
       "      <td>498.840</td>\n",
       "      <td>497.98</td>\n",
       "      <td>480.160</td>\n",
       "      <td>497.490</td>\n",
       "      <td>4316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>491.599</td>\n",
       "      <td>490.040</td>\n",
       "      <td>2014-04-23</td>\n",
       "      <td>496.000</td>\n",
       "      <td>490.03</td>\n",
       "      <td>482.880</td>\n",
       "      <td>490.819</td>\n",
       "      <td>4716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>491.390</td>\n",
       "      <td>491.210</td>\n",
       "      <td>2014-04-22</td>\n",
       "      <td>506.000</td>\n",
       "      <td>491.20</td>\n",
       "      <td>488.800</td>\n",
       "      <td>491.300</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>497.180</td>\n",
       "      <td>497.000</td>\n",
       "      <td>2014-04-21</td>\n",
       "      <td>515.646</td>\n",
       "      <td>497.00</td>\n",
       "      <td>485.000</td>\n",
       "      <td>497.090</td>\n",
       "      <td>8132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>501.420</td>\n",
       "      <td>500.072</td>\n",
       "      <td>2014-04-20</td>\n",
       "      <td>517.995</td>\n",
       "      <td>501.44</td>\n",
       "      <td>492.200</td>\n",
       "      <td>500.746</td>\n",
       "      <td>4921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>507.490</td>\n",
       "      <td>502.531</td>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>513.990</td>\n",
       "      <td>507.50</td>\n",
       "      <td>473.830</td>\n",
       "      <td>505.011</td>\n",
       "      <td>8963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>484.790</td>\n",
       "      <td>482.750</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>509.000</td>\n",
       "      <td>482.75</td>\n",
       "      <td>474.250</td>\n",
       "      <td>483.770</td>\n",
       "      <td>10458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>508.000</td>\n",
       "      <td>506.040</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>538.500</td>\n",
       "      <td>508.00</td>\n",
       "      <td>486.100</td>\n",
       "      <td>507.020</td>\n",
       "      <td>20709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>538.000</td>\n",
       "      <td>537.000</td>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>547.000</td>\n",
       "      <td>538.00</td>\n",
       "      <td>495.000</td>\n",
       "      <td>537.500</td>\n",
       "      <td>29633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>504.970</td>\n",
       "      <td>503.500</td>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>513.900</td>\n",
       "      <td>505.00</td>\n",
       "      <td>452.000</td>\n",
       "      <td>504.235</td>\n",
       "      <td>21013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1410 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ASK        BID       DATE       HIGH      LAST        LOW  \\\n",
       "0      7926.700   7925.800 2018-03-27   8277.800   7926.50   7716.600   \n",
       "1      8187.900   8183.800 2018-03-26   8516.900   8177.40   7835.900   \n",
       "2      8480.800   8479.900 2018-03-25   8674.400   8481.00   8364.800   \n",
       "3      8643.800   8639.700 2018-03-24   9050.300   8639.70   8556.000   \n",
       "4      8690.900   8690.200 2018-03-22   9095.920   8690.90   8450.000   \n",
       "5      8870.100   8870.000 2018-03-21   9177.500   8870.00   8752.000   \n",
       "6      8932.000   8931.900 2018-03-20   9040.000   8932.00   8305.100   \n",
       "7      8500.000   8499.900 2018-03-19   8717.000   8505.00   8085.700   \n",
       "8      8149.100   8148.800 2018-03-18   8300.000   8147.00   7240.000   \n",
       "9      7993.100   7993.000 2018-03-17   8515.900   7993.00   7728.100   \n",
       "10     8488.300   8481.000 2018-03-16   8604.500   8494.30   7902.000   \n",
       "11     8269.000   8268.900 2018-03-15   8418.000   8267.70   7665.100   \n",
       "12     8175.100   8175.000 2018-03-14   9439.600   8175.10   7916.000   \n",
       "13     9150.600   9150.500 2018-03-13   9482.400   9150.60   8822.000   \n",
       "14     9098.500   9098.400 2018-03-12   9900.000   9098.40   8770.000   \n",
       "15     9485.100   9482.100 2018-03-11   9729.000   9485.20   8428.000   \n",
       "16     8807.800   8807.700 2018-03-10   9506.400   8807.70   8670.900   \n",
       "17     9303.000   9302.400 2018-03-09   9428.000   9303.00   8342.000   \n",
       "18     9352.600   9352.500 2018-03-08  10112.000   9352.57   9025.000   \n",
       "19     9884.100   9880.000 2018-03-07  10899.000   9880.00   9400.000   \n",
       "20    10685.000  10683.000 2018-03-06  11553.000  10683.00  10567.000   \n",
       "21    11545.000  11543.000 2018-03-05  11700.000  11545.00  11400.000   \n",
       "22    11535.000  11534.000 2018-03-04  11549.000  11534.00  11050.000   \n",
       "23    11464.000  11463.000 2018-03-03  11530.000  11463.00  11013.000   \n",
       "24    11022.000  11021.000 2018-03-02  11189.000  11022.00  10762.000   \n",
       "25    10940.000  10934.000 2018-03-01  11095.000  10940.00  10210.000   \n",
       "26    10295.000  10294.000 2018-02-28  11065.000  10294.00  10261.000   \n",
       "27    10669.000  10668.000 2018-02-27  10888.000  10668.00  10125.000   \n",
       "28    10301.000  10300.000 2018-02-26  10439.000  10300.00   9359.900   \n",
       "29     9541.000   9536.300 2018-02-25   9840.000   9534.50   9280.400   \n",
       "...         ...        ...        ...        ...       ...        ...   \n",
       "1380    446.970    446.400 2014-05-15    451.400    446.97    442.510   \n",
       "1381    447.400    447.000 2014-05-14    448.000    447.00    437.810   \n",
       "1382    439.000    437.810 2014-05-13    442.000    437.82    434.010   \n",
       "1383    439.410    439.400 2014-05-12    442.000    439.41    431.800   \n",
       "1384    436.850    436.810 2014-05-11    459.650    436.85    430.000   \n",
       "1385    455.200    455.000 2014-05-10    457.000    455.00    448.200   \n",
       "1386    443.490    442.000 2014-05-08    450.590    442.00    438.600   \n",
       "1387    446.000    445.720 2014-05-07    453.600    446.00    424.249   \n",
       "1388    430.900    429.500 2014-05-06    435.390    430.90    419.400   \n",
       "1389    432.237    430.750 2014-05-05    444.400    430.75    425.600   \n",
       "1390    436.900    436.200 2014-05-04    441.950    436.40    429.000   \n",
       "1391    441.380    440.300 2014-05-03    455.000    441.30    430.000   \n",
       "1392    449.850    449.460 2014-05-02    461.670    449.85    443.000   \n",
       "1393    460.090    459.100 2014-05-01    463.530    460.10    446.990   \n",
       "1394    449.370    449.360 2014-04-30    453.600    449.37    432.000   \n",
       "1395    447.000    445.550 2014-04-29    454.000    445.54    434.000   \n",
       "1396    445.500    445.400 2014-04-28    450.000    445.40    423.110   \n",
       "1397    445.910    445.500 2014-04-27    465.600    445.00    440.000   \n",
       "1398    459.000    457.600 2014-04-26    469.190    457.60    449.800   \n",
       "1399    465.955    463.790 2014-04-25    504.960    463.79    441.300   \n",
       "1400    497.980    497.000 2014-04-24    498.840    497.98    480.160   \n",
       "1401    491.599    490.040 2014-04-23    496.000    490.03    482.880   \n",
       "1402    491.390    491.210 2014-04-22    506.000    491.20    488.800   \n",
       "1403    497.180    497.000 2014-04-21    515.646    497.00    485.000   \n",
       "1404    501.420    500.072 2014-04-20    517.995    501.44    492.200   \n",
       "1405    507.490    502.531 2014-04-19    513.990    507.50    473.830   \n",
       "1406    484.790    482.750 2014-04-18    509.000    482.75    474.250   \n",
       "1407    508.000    506.040 2014-04-17    538.500    508.00    486.100   \n",
       "1408    538.000    537.000 2014-04-16    547.000    538.00    495.000   \n",
       "1409    504.970    503.500 2014-04-15    513.900    505.00    452.000   \n",
       "\n",
       "            MID  VOLUME  \n",
       "0      7926.250   49132  \n",
       "1      8185.850   58065  \n",
       "2      8480.350   30079  \n",
       "3      8641.750   44565  \n",
       "4      8690.550   54383  \n",
       "5      8870.050   42946  \n",
       "6      8931.950   55419  \n",
       "7      8499.950   74323  \n",
       "8      8148.950   87116  \n",
       "9      7993.050   50245  \n",
       "10     8484.650   54272  \n",
       "11     8268.950   83733  \n",
       "12     8175.050   77582  \n",
       "13     9150.550   62993  \n",
       "14     9098.450   67217  \n",
       "15     9483.600   70288  \n",
       "16     8807.750   52902  \n",
       "17     9302.700   98498  \n",
       "18     9352.550   67030  \n",
       "19     9882.050   75295  \n",
       "20    10684.000   45055  \n",
       "21    11544.000   26849  \n",
       "22    11534.500   27917  \n",
       "23    11463.500   30574  \n",
       "24    11021.500   29056  \n",
       "25    10937.000   33718  \n",
       "26    10294.500   44130  \n",
       "27    10668.500   39458  \n",
       "28    10300.500   45945  \n",
       "29     9538.650   30710  \n",
       "...         ...     ...  \n",
       "1380    446.685    1892  \n",
       "1381    447.200    3086  \n",
       "1382    438.405    1913  \n",
       "1383    439.405    3454  \n",
       "1384    436.830   11882  \n",
       "1385    455.100    2438  \n",
       "1386    442.745    4046  \n",
       "1387    445.860   10468  \n",
       "1388    430.200    6980  \n",
       "1389    431.493    5940  \n",
       "1390    436.550    4157  \n",
       "1391    440.840    7611  \n",
       "1392    449.655    3298  \n",
       "1393    459.595    5339  \n",
       "1394    449.365    6877  \n",
       "1395    446.275    8521  \n",
       "1396    445.450   16467  \n",
       "1397    445.705    5959  \n",
       "1398    458.300    8578  \n",
       "1399    464.872   30376  \n",
       "1400    497.490    4316  \n",
       "1401    490.819    4716  \n",
       "1402    491.300    3105  \n",
       "1403    497.090    8132  \n",
       "1404    500.746    4921  \n",
       "1405    505.011    8963  \n",
       "1406    483.770   10458  \n",
       "1407    507.020   20709  \n",
       "1408    537.500   29633  \n",
       "1409    504.235   21013  \n",
       "\n",
       "[1410 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pymysql as pms\n",
    "db = pms.connect(\"140.118.126.136\", \"123\", \"1234567890\", \"test\",cursorclass=pms.cursors.DictCursor)\n",
    "cursor = db.cursor()\n",
    "cursor.execute(\"select * from btc_usd order by DATE DESC\")\n",
    "result = cursor.fetchall()\n",
    "btc_data = pd.DataFrame(result)\n",
    "btc_data = btc_data.assign(DATE=pd.to_datetime(btc_data['DATE']))\n",
    "btc_data['VOLUME'] = (pd.to_numeric(btc_data['VOLUME'], errors='coerce').fillna(0))\n",
    "btc_data['VOLUME'] = btc_data['VOLUME'].astype('int64')\n",
    "btc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def some fun tp process data\n",
    "def add_newcol(btc_data): #新增closeoffhigh和volatolity欄位，增加模型訓練的準確度\n",
    "    market_info = btc_data[btc_data['DATE']>='2017-01-01'] #將資料只獲取從2017-01-01之後的內容，存到 market_info\n",
    "    kwargs = { 'CLOSE_OFF_HIGH': lambda x: 2*(x['HIGH'] - x['LAST']) / (x['HIGH'] - x['LOW']) - 1, # 1:收盤接近最低價  -1:收盤接近最高價  \n",
    "          'VOLATILITY': lambda x: (x['HIGH'] - x['LOW']) / (x['MID'])}  #越趨近0越看好\n",
    "    market_info = market_info.assign(**kwargs)\n",
    "    return market_info\n",
    "def create_model_data(btc_data):#選取待會訓練模型所需要的資料\n",
    "    original_model_data = btc_data[[\"DATE\"]+[\"LAST\"]+[\"VOLUME\"]+[\"CLOSE_OFF_HIGH\"]+[\"VOLATILITY\"]]\n",
    "    original_model_data = original_model_data.sort_values(by='DATE')\n",
    "    dic={'DATE':pd.to_datetime(datetime.date.today()),'LAST':[0],'VOLUME':[0],'CLOSE_OFF_HIGH':[0],'VOLATILITY':[0]}\n",
    "    df=pd.DataFrame(dic)\n",
    "    new_model_data=original_model_data\n",
    "    new_model_data=new_model_data.append(df,ignore_index=True)\n",
    "    return original_model_data,new_model_data\n",
    "def create_input_data(data,window_len):#決定訓練時以多少天的大小作訓練(window_len)，以每個為window_len大小的array，作為待會訓練模型的input\n",
    "    norm_cols = ['LAST','VOLUME']\n",
    "    inputs = [] #將Close,Volume以每筆的第一個資料來作正規化，讓值介於-1,1之間\n",
    "    for i in range(len(data)-window_len):\n",
    "        temp_set = data[i:(i+window_len)].copy()\n",
    "        for col in norm_cols:\n",
    "            temp_set.loc[:, col] = temp_set[col]/temp_set[col].iloc[0] - 1 \n",
    "        inputs.append(temp_set)\n",
    "    return inputs\n",
    "def create_output_data(data,window_len):#模型的輸出\n",
    "    return (data['LAST'][window_len:].values / data['LAST'][:-window_len].values) - 1\n",
    "def data_to_np(data):#原本資料的型態為dataframe，這裡將型態轉為numpy array，模型的資料是以這種型態為主\n",
    "    data = [np.array(datas)for datas in data]\n",
    "    data = np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK</th>\n",
       "      <th>BID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LAST</th>\n",
       "      <th>LOW</th>\n",
       "      <th>MID</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>CLOSE_OFF_HIGH</th>\n",
       "      <th>VOLATILITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7926.7</td>\n",
       "      <td>7925.8</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>8277.80</td>\n",
       "      <td>7926.5</td>\n",
       "      <td>7716.6</td>\n",
       "      <td>7926.25</td>\n",
       "      <td>49132</td>\n",
       "      <td>0.251960</td>\n",
       "      <td>0.070803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8187.9</td>\n",
       "      <td>8183.8</td>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>8516.90</td>\n",
       "      <td>8177.4</td>\n",
       "      <td>7835.9</td>\n",
       "      <td>8185.85</td>\n",
       "      <td>58065</td>\n",
       "      <td>-0.002937</td>\n",
       "      <td>0.083192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8480.8</td>\n",
       "      <td>8479.9</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>8674.40</td>\n",
       "      <td>8481.0</td>\n",
       "      <td>8364.8</td>\n",
       "      <td>8480.35</td>\n",
       "      <td>30079</td>\n",
       "      <td>0.249354</td>\n",
       "      <td>0.036508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8643.8</td>\n",
       "      <td>8639.7</td>\n",
       "      <td>2018-03-24</td>\n",
       "      <td>9050.30</td>\n",
       "      <td>8639.7</td>\n",
       "      <td>8556.0</td>\n",
       "      <td>8641.75</td>\n",
       "      <td>44565</td>\n",
       "      <td>0.661339</td>\n",
       "      <td>0.057199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8690.9</td>\n",
       "      <td>8690.2</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>9095.92</td>\n",
       "      <td>8690.9</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>8690.55</td>\n",
       "      <td>54383</td>\n",
       "      <td>0.254087</td>\n",
       "      <td>0.074324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ASK     BID       DATE     HIGH    LAST     LOW      MID  VOLUME  \\\n",
       "0  7926.7  7925.8 2018-03-27  8277.80  7926.5  7716.6  7926.25   49132   \n",
       "1  8187.9  8183.8 2018-03-26  8516.90  8177.4  7835.9  8185.85   58065   \n",
       "2  8480.8  8479.9 2018-03-25  8674.40  8481.0  8364.8  8480.35   30079   \n",
       "3  8643.8  8639.7 2018-03-24  9050.30  8639.7  8556.0  8641.75   44565   \n",
       "4  8690.9  8690.2 2018-03-22  9095.92  8690.9  8450.0  8690.55   54383   \n",
       "\n",
       "   CLOSE_OFF_HIGH  VOLATILITY  \n",
       "0        0.251960    0.070803  \n",
       "1       -0.002937    0.083192  \n",
       "2        0.249354    0.036508  \n",
       "3        0.661339    0.057199  \n",
       "4        0.254087    0.074324  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_info = add_newcol(btc_data)\n",
    "market_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLOSE_OFF_HIGH</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LAST</th>\n",
       "      <th>VOLATILITY</th>\n",
       "      <th>VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.661339</td>\n",
       "      <td>2018-03-24</td>\n",
       "      <td>8639.7</td>\n",
       "      <td>0.057199</td>\n",
       "      <td>44565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.249354</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>8481.0</td>\n",
       "      <td>0.036508</td>\n",
       "      <td>30079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>-0.002937</td>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>8177.4</td>\n",
       "      <td>0.083192</td>\n",
       "      <td>58065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.251960</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>7926.5</td>\n",
       "      <td>0.070803</td>\n",
       "      <td>49132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CLOSE_OFF_HIGH       DATE    LAST  VOLATILITY  VOLUME\n",
       "437        0.661339 2018-03-24  8639.7    0.057199   44565\n",
       "438        0.249354 2018-03-25  8481.0    0.036508   30079\n",
       "439       -0.002937 2018-03-26  8177.4    0.083192   58065\n",
       "440        0.251960 2018-03-27  7926.5    0.070803   49132\n",
       "441        0.000000 2018-03-28     0.0    0.000000       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data,new_model_data = create_model_data(market_info)\n",
    "model_data.head()\n",
    "new_model_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLOSE_OFF_HIGH</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LAST</th>\n",
       "      <th>VOLATILITY</th>\n",
       "      <th>VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-0.145454</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>2287.80</td>\n",
       "      <td>0.082248</td>\n",
       "      <td>19095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2017-06-02</td>\n",
       "      <td>2390.00</td>\n",
       "      <td>0.053223</td>\n",
       "      <td>11467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-0.940120</td>\n",
       "      <td>2017-06-03</td>\n",
       "      <td>2477.20</td>\n",
       "      <td>0.053942</td>\n",
       "      <td>11912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.672180</td>\n",
       "      <td>2017-06-04</td>\n",
       "      <td>2476.20</td>\n",
       "      <td>0.053756</td>\n",
       "      <td>11862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.654740</td>\n",
       "      <td>2017-06-05</td>\n",
       "      <td>2618.91</td>\n",
       "      <td>0.067679</td>\n",
       "      <td>15069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CLOSE_OFF_HIGH       DATE     LAST  VOLATILITY  VOLUME\n",
       "145       -0.145454 2017-06-01  2287.80    0.082248   19095\n",
       "146       -1.000000 2017-06-02  2390.00    0.053223   11467\n",
       "147       -0.940120 2017-06-03  2477.20    0.053942   11912\n",
       "148       -0.672180 2017-06-04  2476.20    0.053756   11862\n",
       "149       -0.654740 2017-06-05  2618.91    0.067679   15069"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_date = '2017-06-01' #將training_set,test_set從這個日期做劃分\n",
    "training_set, test_set = new_model_data[new_model_data['DATE']<split_date], new_model_data[new_model_data['DATE']>=split_date]\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = training_set.drop('DATE', 1) #將Date的欄位刪掉，因為之後不會需要用到它，因為後面要將形式轉為np array，故只留數值的部分\n",
    "test_set = test_set.drop('DATE', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_len = 10 #決定模型要獲取幾天前的數據，隨意選擇\n",
    "norm_cols = ['LAST','VOLUME']\n",
    "LSTM_training_inputs = create_input_data(training_set,10)\n",
    "LSTM_test_inputs = create_input_data(test_set,10)\n",
    "LSTM_training_outputs = create_output_data(training_set,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLOSE_OFF_HIGH</th>\n",
       "      <th>LAST</th>\n",
       "      <th>VOLATILITY</th>\n",
       "      <th>VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023982</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.679045</td>\n",
       "      <td>0.033757</td>\n",
       "      <td>0.045317</td>\n",
       "      <td>0.880509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.242054</td>\n",
       "      <td>0.054717</td>\n",
       "      <td>0.040120</td>\n",
       "      <td>2.050791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.849057</td>\n",
       "      <td>0.073856</td>\n",
       "      <td>0.025518</td>\n",
       "      <td>0.976773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.816901</td>\n",
       "      <td>0.178966</td>\n",
       "      <td>0.099767</td>\n",
       "      <td>6.513362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.031693</td>\n",
       "      <td>0.038061</td>\n",
       "      <td>0.314032</td>\n",
       "      <td>11.763117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>-0.070463</td>\n",
       "      <td>0.171409</td>\n",
       "      <td>7.030083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.937767</td>\n",
       "      <td>-0.060531</td>\n",
       "      <td>0.105767</td>\n",
       "      <td>4.683923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033582</td>\n",
       "      <td>-0.052462</td>\n",
       "      <td>0.058518</td>\n",
       "      <td>3.298447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.343405</td>\n",
       "      <td>-0.065797</td>\n",
       "      <td>0.046179</td>\n",
       "      <td>1.320834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLOSE_OFF_HIGH      LAST  VOLATILITY     VOLUME\n",
       "0       -0.862872  0.000000    0.023982   0.000000\n",
       "1       -0.679045  0.033757    0.045317   0.880509\n",
       "2       -0.242054  0.054717    0.040120   2.050791\n",
       "3       -0.849057  0.073856    0.025518   0.976773\n",
       "4       -0.816901  0.178966    0.099767   6.513362\n",
       "5        0.031693  0.038061    0.314032  11.763117\n",
       "6        0.642857 -0.070463    0.171409   7.030083\n",
       "7       -0.937767 -0.060531    0.105767   4.683923\n",
       "8        0.033582 -0.052462    0.058518   3.298447\n",
       "9       -0.343405 -0.065797    0.046179   1.320834"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_training_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#以 np array的形式做處理，當存以數字的形式\n",
    "LSTM_training_inputs = data_to_np(LSTM_training_inputs)\n",
    "LSTM_test_inputs = data_to_np(LSTM_test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the relevant Keras modules\n",
    "\n",
    "#開始建造LSTM模型\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#neurons=神經元個數(可自訂),epochs=訓練的次數,lose.optimizer都可更改(但結果以這兩個最好)\n",
    "def build_model1(inputs, output_size, neurons, activ_func=\"linear\",\n",
    "                dropout=0.25, loss=\"mse\", optimizer=\"adam\"):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(neurons, input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    #outputlayer\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 2s - loss: 0.0244\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.0142\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.0106\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.0085\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.0049\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.0047\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.0057\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.0048\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.0052\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.0044\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.0035\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.0038\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.0036\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.0037\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.0029\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.0036\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.0027\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.0029\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.0030\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.0026\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.0029\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.0025\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.0029\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.0030\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.0029\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.0028\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.0028\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.0028\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.0027\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.0023\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.0025\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.0026\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.0023\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.0024\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.0021\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.0022\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.0025\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.0021\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.0021\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.0025\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.0025\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.0018\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.0020\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.0019\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.0024\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.0024\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.0018\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.0021\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.0019\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.0020\n"
     ]
    }
   ],
   "source": [
    "# random seed for reproducibility\n",
    "np.random.seed(202)\n",
    "# initialise model architecture\n",
    "bt_model = build_model1(LSTM_training_inputs, output_size=1, neurons = 20)\n",
    "# train model on data\n",
    "# note: eth_history contains information on the training error per epoch\n",
    "bt_history = bt_model.fit(LSTM_training_inputs, \n",
    "                            LSTM_training_outputs, \n",
    "                            epochs=50, batch_size=1, verbose=2, shuffle=True)\n",
    "# #eth_model.save('eth_model%d.h5'%j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEHCAYAAACTC1DDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10df3048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2805.73068788   2883.38156104   2706.57658272   2748.52713082\n",
      "   2552.96058548   2499.59594309   2471.27293196   2540.12090936\n",
      "   2427.87679768   2506.66626375   2660.27434616   2640.4734658\n",
      "   2696.54598832   2717.49100342   2602.57355566   2564.33606529\n",
      "   2536.13480449   2597.33397818   2569.95708561   2523.71913192\n",
      "   2465.21617382   2396.65530026   2431.92200197   2571.51296439\n",
      "   2578.37759542   2653.32168877   2675.71999474   2568.24238936\n",
      "   2633.58280628   2542.3661027    2457.97739029   2467.24296613\n",
      "   2468.21053073   2407.53677602   2320.04222667   2213.79874721\n",
      "   2143.62360661   2211.98778224   2225.81920794   2242.85809754\n",
      "   2586.10585613   2611.1477353    2757.56149937   2744.05440366\n",
      "   2792.43195612   2638.01743984   2628.94978718   2732.80228443\n",
      "   2769.93124037   2733.08942535   2787.69974661   2852.11412811\n",
      "   2782.84469216   2739.63629186   2834.54516459   2868.3835727\n",
      "   3065.42352653   3168.52310002   3313.94130325   3426.6277349\n",
      "   3352.45668793   3467.97314429   3594.11689253   3668.9157758\n",
      "   3884.25572896   4140.14945351   4082.41910398   4304.78903389\n",
      "   4282.54102613   4166.75164455   4252.46838818   4199.4181509\n",
      "   4097.99251041   4146.11645198   4138.9313867    4321.73352826\n",
      "   4347.5169647    4403.12945938   4363.33011097   4470.72031331\n",
      "   4616.6987069    4597.19959177   4740.90428996   4844.21735229\n",
      "   4642.22350273   4676.56835346   4475.78091431   4565.97051001\n",
      "   4670.7646661    4651.5197607    4443.68193886   4411.06487734\n",
      "   4387.04647183   4269.95101837   4191.39647949   4116.34884319\n",
      "   3781.99209213   3913.9630661    3782.56282043   3710.80536858\n",
      "   3831.11718604   3858.4062642    3849.80531064   3769.63675237\n",
      "   3742.42683088   3836.2686955    3774.29633272   3929.15123868\n",
      "   3901.6116035    4165.77969801   4206.57160442   4254.26410306\n",
      "   4397.67504011   4469.32205615   4369.39911053   4379.7864089\n",
      "   4335.4726904    4494.94783974   4456.48995119   4539.73147053\n",
      "   4700.43910568   4763.57826948   4773.92130268   4873.49497274\n",
      "   5156.51913762   5307.22084286   5663.11632118   5661.14526367\n",
      "   5704.89938323   5594.7557199    5797.36066082   5820.90425265\n",
      "   5922.05690682   6036.08973026   6000.39936831   6006.79456121\n",
      "   5749.80460291   5839.40192699   5905.24226367   5814.53229418\n",
      "   5789.95128922   6100.46175833   6128.61776333   6407.0902276\n",
      "   6716.21497303   6808.37137437   7099.25809979   7324.64626329\n",
      "   7223.08368797   7057.58759975   7292.74056938   7364.04124618\n",
      "   7306.85700016   7044.00507535   6801.63889962   6518.66296873\n",
      "   6608.56986101   6620.93946147   7079.16701221   7461.61470914\n",
      "   7632.69987535   7820.37083092   8069.33596087   8211.76351422\n",
      "   8017.79135828   8244.12282109   7996.05858088   8288.39734549\n",
      "   8928.56219637   9538.86457313   9794.87128973   9522.75708505\n",
      "   9852.57184811  10542.55473182  10505.71262121  10644.19982178\n",
      "  11354.89280043  11401.20122802  12654.17965704  14263.23833635\n",
      "  14806.07910347  14552.54238914  14897.02242851  15621.14218044\n",
      "  15610.44630194  15998.03885543  16712.7472055   18243.48274004\n",
      "  18680.39046562  19311.62578068  18228.99689198  17512.45037591\n",
      "  16685.87240434  15212.77957296  14462.64648438  13796.77360958\n",
      "  13202.09116817  14300.16118336  14627.84738541  14555.91419935\n",
      "  14394.4880873   13480.21145165  13832.77789497  13576.00712371\n",
      "  14216.01092863  14777.78661227  15196.04219437  16337.52840757\n",
      "  17037.40619361  16486.02531719  15653.72682452  15156.15246713\n",
      "  15476.79236531  14311.65358154  14083.9112922   14023.59620929\n",
      "  13600.94730854  13388.30471188  12818.22369814  12129.67488289\n",
      "  11548.30267978  11178.10482979  12064.27901745  11580.63290119\n",
      "  11042.12483847  10979.62032855  10858.83513349  11262.50282836\n",
      "  11428.89085674  11716.90317541  11435.76135933  10898.10942167\n",
      "  10812.91199577  10216.63088709   9801.38459229   9507.70268923\n",
      "   8819.24042124   8043.07179928   8410.24228239   7841.84268558\n",
      "   7780.13668227   8167.04084969   8442.69608885   8268.34120399\n",
      "   8633.67067575   8655.71466613   9234.96180058   9846.09644172\n",
      "  10076.28991008  10677.51143017  10487.74945736  11055.58105416\n",
      "  10785.68482769  10779.80460259  10324.12342687  10603.06422496\n",
      "  10190.50267935   9921.68839723  10298.99022937  10656.18809462\n",
      "  10462.78957331  10920.06830585  11150.77013588  11562.92213421\n",
      "  11813.8921988   11632.50797336  11114.05482852  10689.90679979\n",
      "  10158.84466839  10065.46104836   9366.71496987   9484.71456599\n",
      "   9217.92072129   9125.42697728   8685.89144528   8673.7539584\n",
      "   8716.24497175   8339.94783341   8343.58343214   8502.56964839\n",
      "   8757.47624021   8773.39167867   8743.97268652   8736.95705401\n",
      "   8727.03462625   8631.5963367    8407.65970504]\n",
      "155     2936.60\n",
      "156     2543.80\n",
      "157     2681.00\n",
      "158     2374.20\n",
      "159     2385.20\n",
      "160     2423.70\n",
      "161     2630.00\n",
      "162     2479.10\n",
      "163     2568.00\n",
      "164     2747.30\n",
      "165     2601.10\n",
      "166     2675.00\n",
      "167     2692.10\n",
      "168     2485.20\n",
      "169     2462.20\n",
      "170     2397.50\n",
      "171     2495.60\n",
      "172     2511.70\n",
      "173     2490.30\n",
      "174     2426.00\n",
      "175     2330.00\n",
      "176     2437.20\n",
      "177     2550.50\n",
      "178     2560.90\n",
      "179     2601.20\n",
      "180     2597.50\n",
      "181     2453.80\n",
      "182     2541.40\n",
      "183     2496.90\n",
      "184     2311.40\n",
      "         ...   \n",
      "411     9534.50\n",
      "412    10300.00\n",
      "413    10668.00\n",
      "414    10294.00\n",
      "415    10940.00\n",
      "416    11022.00\n",
      "417    11463.00\n",
      "418    11534.00\n",
      "419    11545.00\n",
      "420    10683.00\n",
      "421     9880.00\n",
      "422     9352.57\n",
      "423     9303.00\n",
      "424     8807.70\n",
      "425     9485.20\n",
      "426     9098.40\n",
      "427     9150.60\n",
      "428     8175.10\n",
      "429     8267.70\n",
      "430     8494.30\n",
      "431     7993.00\n",
      "432     8147.00\n",
      "433     8505.00\n",
      "434     8932.00\n",
      "435     8870.00\n",
      "436     8690.90\n",
      "437     8639.70\n",
      "438     8481.00\n",
      "439     8177.40\n",
      "440     7926.50\n",
      "Name: LAST, Length: 286, dtype: float64\n",
      "286 287\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.set_xticks([datetime.date(2017+j,i+1,23)for j in range(2) for i in range(12)])\n",
    "ax1.set_xticklabels([datetime.date(2017+j,i+1,23).strftime('%b %d')for j in range(2)  for i in range(12)],fontsize=9)\n",
    "ax1.plot(model_data[model_data['DATE']>= split_date]['DATE'][window_len:].astype(datetime.datetime),\n",
    "         test_set['LAST'][window_len:-1], label='Actual')\n",
    "ax1.plot(new_model_data[new_model_data['DATE']>= split_date]['DATE'][window_len:].astype(datetime.datetime),\n",
    "         ((np.transpose(bt_model.predict(LSTM_test_inputs))+1) * test_set['LAST'].values[:-window_len])[0], \n",
    "         label='Predicted')\n",
    "#ax1.annotate('MAE: %.4f'%np.mean(np.abs((np.transpose(bt_model.predict(LSTM_test_inputs))+1)-\\\n",
    "#            (test_set['LAST'].values[window_len:])/(test_set['LAST'].values[:-window_len]))), \n",
    "#             xy=(0.75, 0.9),  xycoords='axes fraction',\n",
    "#            xytext=(0.75, 0.9), textcoords='axes fraction')\n",
    "ax1.set_title('Test Set: Single Timepoint Prediction',fontsize=13)\n",
    "ax1.set_ylabel('Bitcoin Price ($)',fontsize=12)\n",
    "ax1.legend(bbox_to_anchor=(0.1, 1), loc=2, borderaxespad=0., prop={'size': 14})\n",
    "plt.show()\n",
    "print(((np.transpose(bt_model.predict(LSTM_test_inputs))+1) * test_set['LAST'].values[:-window_len])[0])\n",
    "print(test_set['LAST'][window_len:-1])\n",
    "print(len(test_set['LAST'][window_len:-1]),len((bt_model.predict(LSTM_test_inputs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model2(inputs, output_size, neurons, activ_func=\"tanh\",\n",
    "                dropout=0.25, loss=\"mse\", optimizer=\"adam\"):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, return_sequences=True, input_shape=(inputs.shape[1], inputs.shape[2]), activation=activ_func))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(neurons, return_sequences=True, activation=activ_func))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(neurons, activation=activ_func))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 6s - loss: 0.0173 - mean_absolute_error: 0.1120\n",
      "Epoch 2/50\n",
      " - 3s - loss: 0.0235 - mean_absolute_error: 0.1136\n",
      "Epoch 3/50\n",
      " - 3s - loss: 0.0144 - mean_absolute_error: 0.0940\n",
      "Epoch 4/50\n",
      " - 3s - loss: 0.0137 - mean_absolute_error: 0.0930\n",
      "Epoch 5/50\n",
      " - 3s - loss: 0.0116 - mean_absolute_error: 0.0867\n",
      "Epoch 6/50\n",
      " - 3s - loss: 0.0112 - mean_absolute_error: 0.0808\n",
      "Epoch 7/50\n",
      " - 3s - loss: 0.0106 - mean_absolute_error: 0.0744\n",
      "Epoch 8/50\n",
      " - 3s - loss: 0.0098 - mean_absolute_error: 0.0722\n",
      "Epoch 9/50\n",
      " - 3s - loss: 0.0095 - mean_absolute_error: 0.0771\n",
      "Epoch 10/50\n",
      " - 3s - loss: 0.0080 - mean_absolute_error: 0.0687\n",
      "Epoch 11/50\n",
      " - 3s - loss: 0.0070 - mean_absolute_error: 0.0597\n",
      "Epoch 12/50\n",
      " - 3s - loss: 0.0085 - mean_absolute_error: 0.0701\n",
      "Epoch 13/50\n",
      " - 3s - loss: 0.0082 - mean_absolute_error: 0.0684\n",
      "Epoch 14/50\n",
      " - 3s - loss: 0.0065 - mean_absolute_error: 0.0591\n",
      "Epoch 15/50\n",
      " - 3s - loss: 0.0070 - mean_absolute_error: 0.0584\n",
      "Epoch 16/50\n",
      " - 3s - loss: 0.0048 - mean_absolute_error: 0.0523\n",
      "Epoch 17/50\n",
      " - 3s - loss: 0.0053 - mean_absolute_error: 0.0552\n",
      "Epoch 18/50\n",
      " - 3s - loss: 0.0045 - mean_absolute_error: 0.0505\n",
      "Epoch 19/50\n",
      " - 3s - loss: 0.0034 - mean_absolute_error: 0.0434\n",
      "Epoch 20/50\n",
      " - 3s - loss: 0.0033 - mean_absolute_error: 0.0427\n",
      "Epoch 21/50\n",
      " - 3s - loss: 0.0034 - mean_absolute_error: 0.0432\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-be8567a56ec7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m bt_history = bt_model.fit(LSTM_training_inputs, \n\u001b[0;32m      8\u001b[0m                             \u001b[0mLSTM_training_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                             epochs=50, batch_size=128, verbose=2, shuffle=True)\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# #eth_model.save('eth_model%d.h5'%j)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# random seed for reproducibility\n",
    "np.random.seed(202)\n",
    "# initialise model architecture\n",
    "bt_model = build_model2(LSTM_training_inputs, output_size=1, neurons = 512)\n",
    "# train model on data\n",
    "# note: eth_history contains information on the training error per epoch\n",
    "bt_history = bt_model.fit(LSTM_training_inputs, \n",
    "                            LSTM_training_outputs, \n",
    "                            epochs=50, batch_size=128, verbose=2, shuffle=True)\n",
    "# #eth_model.save('eth_model%d.h5'%j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.set_xticks([datetime.date(2017+j,i+1,23)for j in range(2) for i in range(12)])\n",
    "ax1.set_xticklabels([datetime.date(2017+j,i+1,23).strftime('%b %d')for j in range(2)  for i in range(12)],fontsize=9)\n",
    "ax1.plot(model_data[model_data['DATE']>= split_date]['DATE'][window_len:].astype(datetime.datetime),\n",
    "         test_set['LAST'][window_len:], label='Actual')\n",
    "ax1.plot(model_data[model_data['DATE']>= split_date]['DATE'][window_len:].astype(datetime.datetime),\n",
    "         ((np.transpose(bt_model.predict(LSTM_test_inputs))+1) * test_set['LAST'].values[:-window_len])[0], \n",
    "         label='Predicted')\n",
    "#ax1.annotate('MAE: %.4f'%np.mean(np.abs((np.transpose(bt_model.predict(LSTM_test_inputs))+1)-\\\n",
    "#            (test_set['LAST'].values[window_len:])/(test_set['LAST'].values[:-window_len]))), \n",
    "#             xy=(0.75, 0.9),  xycoords='axes fraction',\n",
    "#            xytext=(0.75, 0.9), textcoords='axes fraction')\n",
    "ax1.set_title('Test Set: Single Timepoint Prediction',fontsize=13)\n",
    "ax1.set_ylabel('Bitcoin Price ($)',fontsize=12)\n",
    "ax1.legend(bbox_to_anchor=(0.1, 1), loc=2, borderaxespad=0., prop={'size': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random seed for reproducibility\n",
    "np.random.seed(202)\n",
    "# we'll try to predict the closing price for the next 5 days \n",
    "# change this value if you want to make longer/shorter prediction\n",
    "pred_range = 5\n",
    "# initialise model architecture\n",
    "bt_model = build_model1(LSTM_training_inputs, output_size=pred_range, neurons = 20)\n",
    "# model output is next 5 prices normalised to 10th previous closing price\n",
    "LSTM_training_outputs = []\n",
    "for i in range(window_len, len(training_set['LAST'])-pred_range):\n",
    "    LSTM_training_outputs.append((training_set['LAST'][i:i+pred_range].values/\n",
    "                                  training_set['LAST'].values[i-window_len])-1)\n",
    "LSTM_training_outputs = np.array(LSTM_training_outputs)\n",
    "# train model on data\n",
    "# note: eth_history contains information on the training error per epoch\n",
    "bt_history = bt_model.fit(LSTM_training_inputs[:-pred_range], LSTM_training_outputs, \n",
    "                            epochs=50, batch_size=1, verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.set_xticks([datetime.date(2017+j,i+1,20)for j in range(2) for i in range(12)])\n",
    "ax1.set_xticklabels([datetime.date(2017+j,i+1,20).strftime('%b %d') for j in range(2) for i in range(12)],fontsize=9)\n",
    "ax1.plot(model_data[model_data['DATE']>= split_date]['DATE'][10:].astype(datetime.datetime),\n",
    "         test_set['LAST'][window_len:], label='Actual')\n",
    "ax1.plot(model_data[model_data['DATE']>= split_date]['DATE'][10:].astype(datetime.datetime),\n",
    "         ((np.transpose(bt_model.predict(LSTM_test_inputs))+1) * test_set['LAST'].values[:-window_len])[0], \n",
    "         label='Predicted')\n",
    "#ax1.annotate('MAE: %.4f'%np.mean(np.abs((np.transpose(bt_model.predict(LSTM_test_inputs))+1)-\\\n",
    "            #(test_set['LAST'].values[window_len:])/(test_set['LAST'].values[:-window_len]))), \n",
    "             #xy=(0.75, 0.9),  xycoords='axes fraction',\n",
    "            #xytext=(0.75, 0.9), textcoords='axes fraction')\n",
    "ax1.set_title('Test Set: Single Timepoint Prediction',fontsize=13)\n",
    "ax1.set_ylabel('Bitcoin Price ($)',fontsize=12)\n",
    "ax1.legend(bbox_to_anchor=(0.1, 1), loc=2, borderaxespad=0., prop={'size': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# little bit of reformatting the predictions to closing prices\n",
    "\n",
    "bt_pred_prices = ((bt_model.predict(LSTM_test_inputs)[:-pred_range][::pred_range]+1)*\\\n",
    "                   test_set['LAST'].values[:-(window_len + pred_range)][::5].reshape(int(np.ceil((len(LSTM_test_inputs)-pred_range)/float(pred_range))),1))\n",
    "\n",
    "pred_colors = [\"#FF69B4\", \"#5D6D7E\", \"#F4D03F\",\"#A569BD\",\"#45B39D\"]\n",
    "fig, (ax1) = plt.subplots(1,1)\n",
    "ax1.set_xticks([datetime.date(2017+j,i+1,20)for j in range(2) for i in range(12)])\n",
    "ax1.set_xticklabels([datetime.date(2017+j,i+1,20).strftime('%b %d')for j in range(2)  for i in range(12)])\n",
    "ax1.plot(model_data[model_data['DATE']>= split_date]['DATE'][window_len:].astype(datetime.datetime),\n",
    "         test_set['LAST'][window_len:], label='Actual')\n",
    "for i, (bt_pred) in enumerate(bt_pred_prices):\n",
    "    # Only adding lines to the legend once\n",
    "    if i<5:\n",
    "        ax1.plot(model_data[model_data['DATE']>= split_date]['DATE'][window_len:].astype(datetime.datetime)[pred_range:pred_range+pred_range],\n",
    "                 bt_pred, color=pred_colors[i%5], label=\"Predicted\")\n",
    "    else: \n",
    "        ax1.plot(model_data[model_data['DATE']>= split_date]['DATE'][window_len:].astype(datetime.datetime)[i*pred_range:i*pred_range+pred_range],\n",
    "                 bt_pred, color=pred_colors[i%5])\n",
    "ax1.set_title('Test Set: 5 Timepoint Predictions',fontsize=13)\n",
    "ax1.set_ylabel('Bitcoin Price ($)',fontsize=12)\n",
    "ax1.legend(bbox_to_anchor=(0.13, 1), loc=2, borderaxespad=0., prop={'size': 12})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
